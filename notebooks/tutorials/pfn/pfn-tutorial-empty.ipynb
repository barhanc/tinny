{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b104bd8b",
   "metadata": {},
   "source": [
    "# Krótkie wprowadzenie do sieci PFN (Prior-data Fitted Networks)\n",
    "\n",
    "Autor: Bartosz Hanc\n",
    "\n",
    "Klikając w poniższy link możesz otworzyć ten notebook bezpośrednio w środowisku Google Colab\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/barhanc/nn-core/blob/main/notebooks/tutorials/pfn/pfn-tutorial-empty.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738bbaf",
   "metadata": {},
   "source": [
    "## Wykorzystywane biblioteki\n",
    "\n",
    "Będziemy używać jedynie standardowych bibliotek do uczenia maszynowego: NumPy, PyTorch,\n",
    "Scikit-learn, Matplotlib i tqdm do logowania postępów uczenia. Jeśli używasz środowiska Google Colab\n",
    "to wszystkie wymienione biblioteki powinny być domyślnie zainstalowane i dostępne. Jeżeli jednak\n",
    "korzystasz z własnego komputera to wykonanie poniższej komórki zainstaluje wymagane biblioteki (z\n",
    "wyjątkiem PyTorcha) za pomocą Pip'a. Instalacja PyTorcha wymaga osobnej instrukcji - szczegółowe\n",
    "informacje znajdziesz na stronie: [PyTorch - Get Started](https://pytorch.org/get-started/locally/).\n",
    "\n",
    "Notebook był testowany na Pythonie 3.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50445269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26bc702",
   "metadata": {},
   "outputs": [],
   "source": [
    "type DeviceLikeType = str | torch.device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768ea7b",
   "metadata": {},
   "source": [
    "## Wprowadzenie teoretyczne\n",
    "\n",
    "Typowe podejście do problemu głębokiego uczenia nadzorowanego polega na ustaleniu pewnej\n",
    "architektury sieci neuronowej, a następnie uczeniu tej sieci na zbiorze treningowym $D$. W ujęciu\n",
    "statystycznym rezultatem tego procesu jest aproksymacja warunkowego rozkładu prawdopodobieństwa nad\n",
    "wartościami zmiennej odpowiedzi $p_\\theta(y \\mid \\mathbf{x})$, opisanego przez wagi $\\theta$ sieci,\n",
    "które zostały wyznaczone poprzez numeryczną maksymalizację wiarygodności danych $D$. Zauważ, że w\n",
    "tym podejściu sieć neuronowa uczy się przybliżać proces generowania tych konkretnych danych. Jeśli\n",
    "inductive bias naszej architektury nie jest zgodny z rzeczywistym procesem generacji danych, to taka \n",
    "sieć będzie się słabo generalizować.\n",
    "\n",
    "### Prior-data fitting\n",
    "\n",
    "Ideą sieci PFN jest stworzenie modelu, który wprost przybliża rozkład $q_\\theta(y \\mid \\mathbf{x},\n",
    "D)$, tj. rozkład zmiennej objaśnianej dla niewidzianych wcześniej wartości predyktorów $\\mathbf{x}$\n",
    "pod warunkiem całego zbioru danych treningowych. Sieć taka nie modeluje więc wprost żadnego\n",
    "konkretnego procesu generacji danych, lecz potrafi - na podstawie przekazanego na wejściu zbioru\n",
    "danych treningowych i nowego $\\mathbf{x}$ - wyznaczyć rozkład zmiennej objaśnianej dla tego\n",
    "$\\mathbf{x}$. Brzmi to intrygująco, ponieważ taka sieć ma w wagach niejako zaszyty algorytm\n",
    "wnioskowania (Bayesowskiego, jak zobaczymy później). Zauważ, że dla nowych danych $D$ wykonujemy\n",
    "tylko jedną propagację przez sieć, aby uzyskać predykcje; nie występuje tu trening na zbiorze $D$\n",
    "jako taki. \n",
    "\n",
    "Od razu jednak nasuwają się pytania:\n",
    "\n",
    "- dla jakich właściwie zbiorów danych taka sieć będzie wnioskować poprawnie?\n",
    "- jak ją trenować, aby mogła realizować wspomniany algorytm wnioskowania?\n",
    "- jak właściwie skonstruować sieć, aby mogła przyjmować cały zbiór danych jako wejście?\n",
    "\n",
    "Odpowiedzmy najpierw na dwa pierwsze pytania; do trzeciego wrócimy później. Sieć będziemy trenować w\n",
    "taki sposób, aby modelowany przez nią rozkład $q_\\theta(y \\mid \\mathbf{x}, D)$ przybliżał prawdziwy\n",
    "rozkład predykcyjny a posteriori (ang. posterior predictive distribution, PPD) $p(y \\mid \\mathbf{x},\n",
    "D)$ dla danych $D$ generowanych przez procesy pochodzące z pewnego rozkładu a priori nad procesami\n",
    "generującymi dane. Innymi słowy, zakładamy pewien rozkład a priori nad procesami generującymi dane\n",
    "$p(\\phi)$ (gdzie $\\phi$ oznacza parametry tego procesu) oraz rozkład generujący dane $p(D \\mid\n",
    "\\phi)$. Wówczas prawdziwy rozkład PPD jest dany przez\n",
    "\n",
    "$$\n",
    "    p(y \\mid \\mathbf{x}, D) = \\int p(y \\mid \\mathbf{x}, \\phi) p(\\phi \\mid D) \\,\\mathrm{d}\\phi \\propto \\int p(y \\mid \\mathbf{x}, \\phi) p(D \\mid \\phi) p(\\phi) \\,\\mathrm{d}\\phi\n",
    "$$\n",
    "\n",
    "Rozkład ten można wyznaczyć w postaci analitycznej jedynie dla nielicznych prostych modeli (np.\n",
    "regresji Bayesowskiej czy procesów Gaussowskich). Okazuje się jednak, że do wyznaczenia rozkładu\n",
    "$q_\\theta(y \\mid \\mathbf{x}, D)$, który będzie przybliżał prawdziwy rozkład PPD, wystarczy jedynie\n",
    "możliwość próbkowania danych $D$. Istotnie, minimalizacja funkcji straty (Prior-data NLL) postaci\n",
    "\n",
    "$$\n",
    "    \\mathbb{E} [ - \\log q_\\theta(y \\mid \\mathbf{x}, D) ]\n",
    "$$\n",
    "\n",
    "gdzie wartość oczekiwana jest liczona względem $(\\mathbf{x}, y)$ oraz $D$, jest równoważna\n",
    "minimalizacji dywergencji Kullbacka-Leiblera (uśrednionej po rozkładzie łącznym $\\mathbf{x}, D$)\n",
    "między prawdziwym rozkładem PPD a $q_\\theta(y \\mid \\mathbf{x}, D)$. Wytrenowana sieć będzie więc\n",
    "wnioskować poprawnie dla przekazanych danych $D$, jeśli proces, który je wygenerował, jest\n",
    "dostatecznie bliski priora, na którym sieć PFN była trenowana.\n",
    "\n",
    "![PFN Diagram](https://raw.githubusercontent.com/barhanc/nn-core/refs/heads/main/notebooks/tutorials/pfn/pfn.png)\n",
    "\n",
    "Wspomniany rozkład nad procesami może być bardzo prosty lub niezwykle złożony. Jako prosty przykład\n",
    "możemy podać proces generujący zmienne binarne w taki sposób, że punkty $\\mathbf{x}$ są próbkowane z\n",
    "wielowymiarowego rozkładu normalnego, którego wartość oczekiwana może przyjmować jedną z dwóch\n",
    "wartości z jednakowym prawdopodobieństwem. Wszystkie punkty $\\mathbf{x}$ dla jednej wartości\n",
    "oczekiwanej otrzymują klasę 1, a dla drugiej - klasę 0. Rozkład a priori nad tym procesem mógłby na\n",
    "przykład określać rozkład tych dwóch wartości oczekiwanych, będących hiperparametrami procesu.\n",
    "\n",
    "Zauważ, że fakt, iż sieć jest trenowana na próbkach z pewnego rozkładu a priori, jest tutaj\n",
    "niezwykle istotny. Jeśli nasz prior będzie odpowiednio szeroki i dobrze dobrany do danego\n",
    "zagadnienia (np. klasyfikacji na danych tabelarycznych), to trenując sieć jedynie na syntetycznych\n",
    "zbiorach danych, istnieje możliwość uzyskania modelu podstawowego (ang. foundational model), który\n",
    "będzie radził sobie również na rzeczywistych danych - bez jakiegokolwiek dalszego trenowania (czy\n",
    "raczej fine-tuningu) na nich.\n",
    "\n",
    "Jest to zasadnicza idea stojąca za modelem TabPFN, zaproponowanym właśnie jako foundational model do\n",
    "klasyfikacji na danych tabelarycznych. Był on trenowany na syntetycznych zbiorach danych\n",
    "próbkowanych ze złożonego priora (będącego mieszaniną losowych modeli przyczynowych i sieci\n",
    "Bayesowskich) i w różnych benchmarkach - pomimo pewnych ograniczeń - bez trudu konkuruje z tak\n",
    "uznanymi modelami jak XGBoost, LightGBM czy CatBoost.\n",
    "\n",
    "![TabPFN Diagram](https://raw.githubusercontent.com/barhanc/nn-core/refs/heads/main/notebooks/tutorials/pfn/tab_pfn.png)\n",
    "\n",
    "### Linki\n",
    "\n",
    "- Artykuł wprowadzający sieci PFN [https://arxiv.org/pdf/2112.10510](https://arxiv.org/pdf/2112.10510)\n",
    "- Artykuł wprowadzający model TabPFN (v1) [https://arxiv.org/pdf/2207.01848](https://arxiv.org/pdf/2207.01848)\n",
    "- Artykuł (w Nature) wprowadzający model TabPFN (v2) [https://www.nature.com/articles/s41586-024-08328-6](https://www.nature.com/articles/s41586-024-08328-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f6a79-eb11-4f69-9720-00467390551b",
   "metadata": {},
   "source": [
    "#### Zadanie 1.\n",
    "\n",
    "We wstępie teoretycznym nie odpowiedzieliśmy na jedno zasadnicze pytanie - jak właściwie\n",
    "skonstruować sieć PFN?\n",
    "\n",
    "Po pierwsze, sieć taka ma zwracać rozkład prawdopodobieństwa $q_\\theta(y \\mid \\mathbf{x}, D)$, co w\n",
    "ogólności dla rozkładów ciągłych jest trudne do uzyskania (patrz: artykuł wprowadzający sieci PFN,\n",
    "aby zobaczyć możliwe rozwiązanie dla rozkładów ciągłych wykorzystujące sumy Riemanna). Dlatego też\n",
    "zajmiemy się prostszym przypadkiem rozkładów dyskretnych, które mogą być w pełni opisane przez\n",
    "skończony zbiór prawdopodobieństw. W szczególności zaimplementujemy sieć PFN do klasyfikacji\n",
    "binarnej, która będzie zwracać prawdopodobieństwa klasy pozytywnej, tj. $q_\\theta(y = 1 \\mid\n",
    "\\mathbf{x}, D)$, a więc będzie modelować rozkład Bernoulliego.\n",
    "\n",
    "Po drugie, sieć PFN musi przyjmować na swoje wejście cały zbiór danych treningowych $D$ oraz wektor\n",
    "cech $\\mathbf{x}$, dla którego wykonujemy predykcję. W teorii mogłaby to być nawet zwykła sieć MLP,\n",
    "jednak w praktyce stosuje się architektury typu Transformer. Będziemy zakładać, że pojedynczy punkt\n",
    "danych wejściowych jest reprezentowany przez wektor o wymiarze `num_features`, a więc zbiór $D$ może\n",
    "być reprezentowany w postaci macierzy o wymiarach `(train_size, num_features + 1)` - z dodatkową\n",
    "kolumną na etykietę klasy.\n",
    "\n",
    "W oryginalnej pracy o PFN autorzy wykorzystali architekturę decoder-only Transformer z odpowiednio\n",
    "skonstruowaną maską. W naszym przypadku użyjemy pełnej architektury enkoder-dekoder. Wejściem do\n",
    "enkodera będzie odpowiednio osadzony (embedded) zbiór danych treningowych w postaci macierzy\n",
    "`(train_size, dim_model)`. Wejściem dekodera będzie natomiast osadzony zbiór nowych punktów, dla\n",
    "których chcemy wykonać predykcję, przekazany jako macierz `(query_size, dim_model)` (będziemy\n",
    "nazywać te punkty zapytaniami - queries).\n",
    "\n",
    "![Transformer Architecture](https://upload.wikimedia.org/wikipedia/commons/5/5f/Transformer%2C_stacked_layers_and_sublayers.png)\n",
    "\n",
    "Zauważmy, że taka architektura jest bardzo naturalna dla naszego problemu. Wyjście enkodera -\n",
    "zależne jedynie od zbioru treningowego - ,,programuje'' wagi dekodera, który dokonuje predykcji dla\n",
    "nowych obserwacji. Dodatkowo wyjścia enkodera i dekodera są ekwiwariantne względem permutacji\n",
    "odpowiednich wierszy danych (nie stosujemy tutaj żadnego kodowania pozycyjnego). W przypadku\n",
    "enkodera nie używamy również żadnej maski atencji, natomiast w przypadku dekodera ograniczamy\n",
    "atencję każdego zapytania wyłącznie do niego samego (tzn. nie chcemy wykorzystywać informacji o\n",
    "korelacjach między punktami w zbiorze testowym).\n",
    "\n",
    "> **Zadanie:**\n",
    "> Poniższy kod implementuje opisaną architekturę. Zapoznaj się z nim (w szczególności ze sposobem\n",
    "> obliczania osadzeń) i uzupełnij brakujący fragment związany ze skonstruowaniem odpowiedniej maski\n",
    "> atencji dla dekodera. Zastanów się jakie ograniczenia ma taka architektura - w szczególności\n",
    "> związane z możliwą liczbą próbek w zbiorze treningowym / testowym (zapytań) oraz z liczbą cech.\n",
    "> Jak możnaby rozwiązać te ograniczenia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliPFN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        dim_model: int,\n",
    "        dim_feedforward: int,\n",
    "        num_heads: int,\n",
    "        num_encoder_layers: int,\n",
    "        num_decoder_layers: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.map_src_X = nn.Linear(num_features, dim_model)\n",
    "        self.map_tgt_X = nn.Linear(num_features, dim_model)\n",
    "        self.map_src_y = nn.Linear(1, dim_model)\n",
    "        self.map_out = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_feedforward),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim_feedforward, 1),\n",
    "        )\n",
    "\n",
    "        # For details about the Transformer implementation in PyTorch as well as the constructor and\n",
    "        # `.forward()` method arguments see:\n",
    "        # https://docs.pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, X_train: Tensor, y_train: Tensor, X_query: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_train (Tensor): Shape `(batch_size, train_size, num_features)`\n",
    "            y_train (Tensor): Shape `(batch_size, train_size, 1)`\n",
    "            X_query (Tensor): Shape `(batch_size, query_size, num_features)`\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Shape `(batch_size, query_size, 1)`\n",
    "        \"\"\"\n",
    "        assert X_train.ndim == 3\n",
    "        assert y_train.ndim == 3\n",
    "        assert X_query.ndim == 3\n",
    "        assert X_train.size(0) == y_train.size(0) == X_query.size(0)\n",
    "        assert X_train.size(2) == X_query.size(2) == self.num_features\n",
    "        assert X_train.size(1) == y_train.size(1)\n",
    "        assert y_train.size(2) == 1\n",
    "\n",
    "        # TODO: Construct mask for the decoder\n",
    "        tgt_mask = ...\n",
    "        raise NotImplementedError\n",
    "\n",
    "        src = self.map_src_X(X_train) + self.map_src_y(y_train)\n",
    "        tgt = self.map_tgt_X(X_query)\n",
    "        out = self.transformer(src, tgt, tgt_mask=tgt_mask.to(tgt))\n",
    "        out = self.map_out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_proba(self, X_train: Tensor, y_train: Tensor, X_query: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_train (Tensor): Shape `(train_size, num_features)`\n",
    "            y_train (Tensor): Shape `(train_size, 1)`\n",
    "            X_query (Tensor): Shape `(query_size, num_features)`\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Shape `(query_size, 1)`\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "\n",
    "        X_train = X_train.unsqueeze(0)\n",
    "        y_train = y_train.unsqueeze(0)\n",
    "        X_query = X_query.unsqueeze(0)\n",
    "\n",
    "        logits: Tensor = self(X_train, y_train, X_query)\n",
    "\n",
    "        return logits.sigmoid().squeeze(0)\n",
    "\n",
    "    def predict(self, X_train: Tensor, y_train: Tensor, X_query: Tensor, threshold: float = 0.5) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_train (Tensor): Shape `(train_size, num_features)`\n",
    "            y_train (Tensor): Shape `(train_size, 1)`\n",
    "            X_query (Tensor): Shape `(query_size, num_features)`\n",
    "            threshold (float): Probability value, used to convert probabilistic outputs into\n",
    "                               concrete class labels.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Shape `(query_size, 1)`\n",
    "        \"\"\"\n",
    "        assert 0.0 < threshold < 1.0\n",
    "        return self.predict_proba(X_train, y_train, X_query) > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35624a28-a3ba-4ad3-acae-8596bbcedc84",
   "metadata": {},
   "source": [
    "#### Zadanie 2.\n",
    "\n",
    "Spróbujemy wytrenować teraz nasz prosty model PFN dla pewnego priora zadań klasyfikacji binarnej. Ze\n",
    "względu na ograniczenia czasu i zasobów obliczeniowych podczas laboratorium rozważymy tylko bardzo\n",
    "proste problemy klasyfikacji na płaszczyźnie (tj. dla `num_features=2`). Dodatkowym, edukacyjnym\n",
    "atutem takiego podejścia będzie możliwość wizualnego zbadania granic decyzyjnych, czyli tak naprawdę\n",
    "wizualizację przybliżonego rozkładu PPD, jaki oblicza sieć PFN.\n",
    "\n",
    "Poniższa komórka zawiera implementacje pomocniczych funkcji do rysowania wykresów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edaa77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "def plot_pfn_decision_boundary(\n",
    "    ax: Axes,\n",
    "    pfn: BernoulliPFN,\n",
    "    X_train: Tensor,\n",
    "    X_query: Tensor,\n",
    "    y_train: Tensor,\n",
    "    y_query: Tensor,\n",
    "    device: DeviceLikeType,\n",
    ") -> None:\n",
    "    assert X_train.ndim == 2\n",
    "    assert X_query.ndim == 2\n",
    "    assert y_train.ndim == 2\n",
    "    assert y_query.ndim == 2\n",
    "    assert X_train.size(1) == 2\n",
    "    assert X_query.size(1) == 2\n",
    "    assert y_train.size(1) == 1\n",
    "    assert y_query.size(1) == 1\n",
    "\n",
    "    # --- Compute mesh limits ---\n",
    "    x_min = min(X_train[:, 0].min().item(), X_query[:, 0].min().item())\n",
    "    x_max = max(X_train[:, 0].max().item(), X_query[:, 0].max().item())\n",
    "    y_min = min(X_train[:, 1].min().item(), X_query[:, 1].min().item())\n",
    "    y_max = max(X_train[:, 1].max().item(), X_query[:, 1].max().item())\n",
    "\n",
    "    margin_x = 0.05 * (x_max - x_min)\n",
    "    margin_y = 0.05 * (y_max - y_min)\n",
    "\n",
    "    x_min -= margin_x\n",
    "    x_max += margin_x\n",
    "    y_min -= margin_y\n",
    "    y_max += margin_y\n",
    "\n",
    "    # --- Construct mesh ---\n",
    "    steps = 50\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, steps), np.linspace(y_min, y_max, steps))\n",
    "    mesh = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float().to(device)\n",
    "\n",
    "    # --- Compute probability values at mesh points ---\n",
    "    probas = pfn.predict_proba(X_train, y_train, mesh).cpu().numpy()\n",
    "    probas = probas.reshape(xx.shape)\n",
    "\n",
    "    # --- Plot probability contours ---\n",
    "    ax.contourf(xx, yy, probas, alpha=0.3, cmap=\"PiYG\", vmin=0, vmax=1)\n",
    "    cs = ax.contour(xx, yy, probas, cmap=\"PiYG\", vmin=0, vmax=1)\n",
    "    ax.clabel(cs, inline=True, fontsize=8)\n",
    "\n",
    "    # --- Plot training and query points ---\n",
    "    ax.scatter(\n",
    "        X_train.cpu().numpy()[:, 0],\n",
    "        X_train.cpu().numpy()[:, 1],\n",
    "        c=y_train.cpu().numpy().flatten(),\n",
    "        edgecolors=\"gold\",\n",
    "        cmap=\"PiYG\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        X_query.cpu().numpy()[:, 0],\n",
    "        X_query.cpu().numpy()[:, 1],\n",
    "        c=y_query.cpu().numpy().flatten(),\n",
    "        edgecolors=\"k\",\n",
    "        cmap=\"PiYG\",\n",
    "    )\n",
    "\n",
    "    # --- Make nice legend ---\n",
    "    train_handle = Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        markerfacecolor=\"none\",\n",
    "        markeredgecolor=\"gold\",\n",
    "        markersize=8,\n",
    "        label=\"Train\",\n",
    "    )\n",
    "    query_handle = Line2D(\n",
    "        [],\n",
    "        [],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        markerfacecolor=\"none\",\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=8,\n",
    "        label=\"Test\",\n",
    "    )\n",
    "    ax.legend(handles=[train_handle, query_handle], loc=\"best\")\n",
    "\n",
    "\n",
    "def plot_loss_hist(ax: Axes, loss_hist: Sequence[float], ylabel: str = \"\") -> None:\n",
    "    ax.plot(loss_hist)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da1298-9a0c-462a-9d72-5b53075c8b2a",
   "metadata": {},
   "source": [
    "Nie będziemy również sami implementować funkcji generującej syntetyczne dane. Wykorzystamy w tym\n",
    "celu możliwości, jakie dostarcza biblioteka Scikit-learn. W szczególności skorzystamy z funkcji\n",
    "[sklearn.datasets.make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)\n",
    ", która pozwala na elastyczne tworzenie syntetycznych zbiorów danych do zadań klasyfikacji binarnej.\n",
    "Więcej o dokładnym sposobie generowania danych można przeczytać w dokumentacji pod powyższym\n",
    "linkiem. Trening modelu będzie polegał na: próbkowaniu w każdej epoce batcha danych ze\n",
    "zdefiniowanego priora zadań klasyfikacyjnych oraz minimalizacji zdefiniowanej wcześniej funkcji\n",
    "straty Prior-data NLL. Dodatkowo ustalimy pewien zbiór danych spróbkowany z tego samego priora, na\n",
    "którym będziemy wizualizować, jak zmienia się aproksymowany przez sieć PFN rozkład PPD podczas\n",
    "kolejnych etapów treningu.\n",
    "\n",
    "> **Zadanie:** Poniższy kod implementuje pętlę treningową zgodnie z podanym opisem. Zapoznaj się z\n",
    "> nim i uzupełnij brakujące fragmenty związane z: generacją syntetycznych zbiorów danych oraz\n",
    "> obliczaniem wartości funkcji straty. Uruchom trening i zaobserwuj, jak zmienia się rozkład\n",
    "> $q_\\theta(y \\mid \\mathbf{x}, D)$ na ustalonym zbiorze. Co możesz powiedzieć o przebiegu treningu i\n",
    "> zachowaniu modelu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338bd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from IPython.display import clear_output, display\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "\n",
    "# NOTE: If you don't have access to a GPU or you're having difficulties to train the model in a\n",
    "# reasonble amount of time, change the prior to a simpler one like `make_blobs()` with `centers=2`\n",
    "# (for binary classification) and lower the number of epochs to ~200.\n",
    "\n",
    "# --- Define prior distribution over binary classification tasks ---\n",
    "# sample_from_prior = lambda n_samples: make_blobs(n_samples, centers=2)\n",
    "sample_from_prior = lambda n_samples: make_classification(n_samples, n_features=2, n_redundant=0)\n",
    "\n",
    "# --- Define training parameters ---\n",
    "batch_size = 256\n",
    "num_epochs = 500\n",
    "\n",
    "train_size = 100  # No. data points used for training\n",
    "query_size = 50  # No. data points used for testing (size of the hold-out set)\n",
    "n_samples = train_size + query_size  # No. data points to sample for a given clasif. task\n",
    "\n",
    "# --- Define model ---\n",
    "pfn = BernoulliPFN(\n",
    "    num_features=2,\n",
    "    dim_model=256,\n",
    "    dim_feedforward=512,\n",
    "    num_heads=8,\n",
    "    num_decoder_layers=2,\n",
    "    num_encoder_layers=2,\n",
    ").to(device)\n",
    "\n",
    "# --- Define optimizer ---\n",
    "optimizer = torch.optim.AdamW(pfn.parameters(), lr=3e-4)\n",
    "\n",
    "# --- Prepare fixed data on which we will monitor the PPD approximated by PFN ---\n",
    "X_fixed, y_fixed = sample_from_prior(n_samples=300)\n",
    "\n",
    "X_fixed = torch.from_numpy(X_fixed).float().to(device)\n",
    "y_fixed = torch.from_numpy(y_fixed).float().unsqueeze(-1).to(device)\n",
    "\n",
    "X_train_fixed = X_fixed[:train_size, :]\n",
    "X_query_fixed = X_fixed[train_size:, :]\n",
    "y_train_fixed = y_fixed[:train_size, :]\n",
    "y_query_fixed = y_fixed[train_size:, :]\n",
    "\n",
    "fixed_data = (X_train_fixed, X_query_fixed, y_train_fixed, y_query_fixed)\n",
    "\n",
    "# ---\n",
    "loss_hist: list[float] = []\n",
    "\n",
    "# NOTE: This flag controls whether to plot live animation during training\n",
    "# WARN: You may experience some flickering when using Google Colab env\n",
    "visualize: bool = True\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "\n",
    "# ################################################\n",
    "# ##########     Training Loop     ###############\n",
    "# ################################################\n",
    "\n",
    "for epoch in (pbar := trange(num_epochs)):\n",
    "    pfn.train()\n",
    "\n",
    "    # --- Sample batch of classification tasks from the prior ---\n",
    "    # TODO: Implement sampling from the prior\n",
    "    X, y = ..., ... # Shape: `(batch_size, num_samples, num_features)`, `(batch_size, num_samples, 1)`\n",
    "    raise NotImplementedError\n",
    "    X_train, y_train = X[:, :train_size, :], y[:, :train_size, :]\n",
    "    X_query, y_query = X[:, train_size:, :], y[:, train_size:, :]\n",
    "\n",
    "    # --- Train model ---\n",
    "    # TODO: Compute loss\n",
    "    loss = ...\n",
    "    raise NotImplementedError\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # --- Log progress ---\n",
    "    loss_hist.append(loss.item())\n",
    "    pbar.set_description(f\"Epoch {epoch+1:>5d} | Loss {loss.item():.3f}\")\n",
    "\n",
    "    # --- Visualize the PPD approximated by PFN on a fixed dataset ---\n",
    "    acc = accuracy_score(\n",
    "        y_true=y_query_fixed.cpu().numpy(),\n",
    "        y_pred=pfn.predict(X_train_fixed, y_train_fixed, X_query_fixed).cpu().numpy(),\n",
    "    )\n",
    "\n",
    "    if visualize:\n",
    "        clear_output(wait=True)\n",
    "        ax[0].clear()\n",
    "        ax[1].clear()\n",
    "        ax[1].set_title(f\"Accuracy {acc:.2%}\")\n",
    "        plot_loss_hist(ax[0], loss_hist, ylabel=\"Prior-data NLL\")\n",
    "        plot_pfn_decision_boundary(ax[1], pfn, *fixed_data, device)\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c15e3d-9803-4642-a6c5-bd30a8818b69",
   "metadata": {},
   "source": [
    "#### Zadanie 3.\n",
    "\n",
    "Na zakończenie sprawdzimy jak wytrenowany model radzi sobie na różnych datasetach spróbkowanych z\n",
    "priora i porównamy go z innym elastycznym modelem - GBDT. Dodatkowo przyjrzymy się różnicom w\n",
    "granicach decyzyjnych obu modeli. Zauważ, że dla nowych datasetów sieć PFN wykonuje tylko jedną\n",
    "propagację w przód, aby wyznaczyć predykcje, natomiast model GBDT musi być wytrenowany osobno na\n",
    "każdym spróbkowanym zbiorze.\n",
    "\n",
    "> **Zadanie:** Poniższe dwie komórki zawierają kod, który losuje ze zdefiniowanego wcześniej priora\n",
    "> zbiór danych, dokonuje jego podziału na zbiór treningowy i testowy, po czym wyznacza dokładność na\n",
    "> zbiorze testowym i rysuje granice decyzyjne dla wytrenowanej sieci PFN i dostrojonego modelu GBDT\n",
    "> z biblioteki Scikit-learn. Wykonaj poniższe komórki kilka razy i zaobserwuj wyniki. Co możesz\n",
    "> powiedzieć o granicach decyzyjnych obu modeli? Który model wg. Ciebie lepiej generalizuje?\n",
    "> Opcjonalnie możesz powtórzyć eksperyment na innym zbiorze danych (klasyfikacji binarnej z dwoma\n",
    "> predyktorami), który nie pochodzi z priora, na którym trenowaliśmy sieć PFN. Jak teraz wyglądają\n",
    "> wyniki?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3529bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_X, data_y = sample_from_prior(n_samples=300)\n",
    "X_train, X_query, y_train, y_query = train_test_split(data_X, data_y, train_size=train_size)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float().to(device)\n",
    "X_query = torch.from_numpy(X_query).float().to(device)\n",
    "y_train = torch.from_numpy(y_train).unsqueeze(-1).float().to(device)\n",
    "y_query = torch.from_numpy(y_query).unsqueeze(-1).float().to(device)\n",
    "\n",
    "acc = accuracy_score(\n",
    "    y_true=y_query.cpu().numpy(),\n",
    "    y_pred=pfn.predict(X_train, y_train, X_query).cpu().numpy(),\n",
    ")\n",
    "print(f\"Accuracy {acc:.2%}\")\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plot_pfn_decision_boundary(ax, pfn, X_train, X_query, y_train, y_query, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bc339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = GradientBoostingClassifier()\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.2, 1.0],\n",
    "    \"max_depth\": [3, 5, 7, None],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "clf.fit(X_train.cpu().numpy(), y_train.cpu().numpy().squeeze())\n",
    "\n",
    "acc = accuracy_score(\n",
    "    y_true=y_query.cpu().numpy().squeeze(),\n",
    "    y_pred=clf.predict(X_query.cpu().numpy()),\n",
    ")\n",
    "print(f\"Accuracy {acc:.2%}\")\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(clf, data_X, cmap=\"PiYG\", alpha=0.3)\n",
    "disp.ax_.scatter(\n",
    "    X_train.cpu().numpy()[:, 0],\n",
    "    X_train.cpu().numpy()[:, 1],\n",
    "    c=y_train.cpu().numpy().squeeze(),\n",
    "    edgecolors=\"gold\",\n",
    "    cmap=\"PiYG\",\n",
    ")\n",
    "disp.ax_.scatter(\n",
    "    X_query.cpu().numpy()[:, 0],\n",
    "    X_query.cpu().numpy()[:, 1],\n",
    "    c=y_query.cpu().numpy().squeeze(),\n",
    "    edgecolors=\"k\",\n",
    "    cmap=\"PiYG\",\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
